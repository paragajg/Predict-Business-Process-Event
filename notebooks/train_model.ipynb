{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM Network to Predict Occurrence of Next Event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Dask for lazy loading and computation of data\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "from dask import delayed\n",
    "import dask.array as da\n",
    "\n",
    "#Word embedding\n",
    "from gensim.models import Word2Vec\n",
    "# Keras DeepLearning Framework\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- log_file.csv is a transformed version of orignal event log data in xes format\n",
    "- Orignal dataset by:\n",
    "- van Dongen, B.F. (Boudewijn) (2017) BPI Challenge 2017. Eindhoven University of Technology. Dataset. https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"log_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trace:concept:name</th>\n",
       "      <th>trace:ApplicationType</th>\n",
       "      <th>trace:LoanGoal</th>\n",
       "      <th>trace:RequestedAmount</th>\n",
       "      <th>caseid</th>\n",
       "      <th>event:concept:name</th>\n",
       "      <th>event:org:resource</th>\n",
       "      <th>event:EventID</th>\n",
       "      <th>event:lifecycle:transition</th>\n",
       "      <th>...</th>\n",
       "      <th>event:EventOrigin</th>\n",
       "      <th>event:FirstWithdrawalAmount</th>\n",
       "      <th>event:MonthlyCost</th>\n",
       "      <th>event:Accepted</th>\n",
       "      <th>event:CreditScore</th>\n",
       "      <th>event:OfferedAmount</th>\n",
       "      <th>event:Selected</th>\n",
       "      <th>event:NumberOfTerms</th>\n",
       "      <th>event:OfferID</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>A_Create Application</td>\n",
       "      <td>User_1</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>complete</td>\n",
       "      <td>...</td>\n",
       "      <td>Application</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>A_Submitted</td>\n",
       "      <td>User_1</td>\n",
       "      <td>ApplState_1582051990</td>\n",
       "      <td>complete</td>\n",
       "      <td>...</td>\n",
       "      <td>Application</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>W_Handle leads</td>\n",
       "      <td>User_1</td>\n",
       "      <td>Workitem_1298499574</td>\n",
       "      <td>schedule</td>\n",
       "      <td>...</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>W_Handle leads</td>\n",
       "      <td>User_1</td>\n",
       "      <td>Workitem_1673366067</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>...</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>W_Complete application</td>\n",
       "      <td>User_1</td>\n",
       "      <td>Workitem_1493664571</td>\n",
       "      <td>schedule</td>\n",
       "      <td>...</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652823628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     trace:concept:name trace:ApplicationType  \\\n",
       "0           0  Application_652823628            New credit   \n",
       "1           1  Application_652823628            New credit   \n",
       "2           2  Application_652823628            New credit   \n",
       "3           3  Application_652823628            New credit   \n",
       "4           4  Application_652823628            New credit   \n",
       "\n",
       "           trace:LoanGoal  trace:RequestedAmount                 caseid  \\\n",
       "0  Existing loan takeover                20000.0  Application_652823628   \n",
       "1  Existing loan takeover                20000.0  Application_652823628   \n",
       "2  Existing loan takeover                20000.0  Application_652823628   \n",
       "3  Existing loan takeover                20000.0  Application_652823628   \n",
       "4  Existing loan takeover                20000.0  Application_652823628   \n",
       "\n",
       "       event:concept:name event:org:resource          event:EventID  \\\n",
       "0    A_Create Application             User_1  Application_652823628   \n",
       "1             A_Submitted             User_1   ApplState_1582051990   \n",
       "2          W_Handle leads             User_1    Workitem_1298499574   \n",
       "3          W_Handle leads             User_1    Workitem_1673366067   \n",
       "4  W_Complete application             User_1    Workitem_1493664571   \n",
       "\n",
       "  event:lifecycle:transition  ... event:EventOrigin  \\\n",
       "0                   complete  ...       Application   \n",
       "1                   complete  ...       Application   \n",
       "2                   schedule  ...          Workflow   \n",
       "3                   withdraw  ...          Workflow   \n",
       "4                   schedule  ...          Workflow   \n",
       "\n",
       "  event:FirstWithdrawalAmount event:MonthlyCost  event:Accepted  \\\n",
       "0                         NaN               NaN             NaN   \n",
       "1                         NaN               NaN             NaN   \n",
       "2                         NaN               NaN             NaN   \n",
       "3                         NaN               NaN             NaN   \n",
       "4                         NaN               NaN             NaN   \n",
       "\n",
       "   event:CreditScore event:OfferedAmount  event:Selected  event:NumberOfTerms  \\\n",
       "0                NaN                 NaN             NaN                  NaN   \n",
       "1                NaN                 NaN             NaN                  NaN   \n",
       "2                NaN                 NaN             NaN                  NaN   \n",
       "3                NaN                 NaN             NaN                  NaN   \n",
       "4                NaN                 NaN             NaN                  NaN   \n",
       "\n",
       "  event:OfferID         Id  \n",
       "0           NaN  652823628  \n",
       "1           NaN  652823628  \n",
       "2           NaN  652823628  \n",
       "3           NaN  652823628  \n",
       "4           NaN  652823628  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group events\n",
    "- Group events part of same transaction\n",
    "- In absence of known final event in the sequence , added event type: 'End' after occurrence of last event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "event_grouped = df.groupby('Id')[\"event:concept:name\"].apply(list)\n",
    "event_grouped = event_grouped.map_partitions(lambda x: x + [\"End\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy loading of events for training Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_events(event_list):\n",
    "    for x in range(event_list.npartitions):\n",
    "            events = event_list.get_partition(x).compute()\n",
    "            events = events.tolist()\n",
    "            for x in events:\n",
    "                yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_Sequence():\n",
    "    '''\n",
    "    Streaming class to generate grouped events in a lazy way to avoid issues of RAM \n",
    "    running out of Memory.\n",
    "    '''\n",
    "    def __init__(self, generator_function,event_list):\n",
    "        self.event_list = event_list\n",
    "        self.generator_function = generator_function\n",
    "        self.generator = self.generator_function(self.event_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # reset the generator\n",
    "        self.generator = self.generator_function(self.event_list)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        result = next(self.generator)\n",
    "        if result is None:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate = generate_Sequence(gen_events,event_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = Word2Vec(iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0423 15:00:44.465139 140633082271488 smart_open_lib.py:379] this function is deprecated, use smart_open.open instead\n"
     ]
    }
   ],
   "source": [
    "w2vmodel.save('w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size / Length of Each Word Vector: 100\n"
     ]
    }
   ],
   "source": [
    "print('Size / Length of Each Word Vector: %s'%w2vmodel.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Distinct Events in the Journey of a Transaction: 27\n"
     ]
    }
   ],
   "source": [
    "print('Count of Distinct Events in the Journey of a Transaction: %s'%len(w2vmodel.wv.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Event Embedding Matrix to be used in training of LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros(shape = (len(w2vmodel.wv.vocab),w2vmodel.vector_size))\n",
    "\n",
    "for i in range(len(w2vmodel.wv.vocab)):\n",
    "    embedding_matrix[i] = w2vmodel.wv[w2vmodel.wv.index2word[i]]\n",
    "\n",
    "#print(embedding_matrix.shape)\n",
    "embedding_matrix[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data streaming pipeline for inputs to LSTM Network\n",
    "- Delayed Function\n",
    "- Delayed funciton output - X, y\n",
    "- Rechunk the dask array to size == Batch Size to be used for Training Model (512 in current \n",
    "    scenario)\n",
    "- Generator Function to initiate above computation graph and feed data in batch size of 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_feed(series):\n",
    "    X_temp , y_temp = [], []\n",
    "    for event in series:\n",
    "        for i in range(1, len(event)):\n",
    "            temp_x = event[0:i]\n",
    "            temp_x = [w2vmodel.wv.vocab.get(x).index for x in temp_x]\n",
    "            #print(temp_x)\n",
    "            X_temp.append(temp_x)\n",
    "            temp_y = w2vmodel.wv.vocab.get(event[i]).index\n",
    "            y_temp.append(temp_y)\n",
    "    \n",
    "    X_events = pad_sequences(X_temp,maxlen= 50)\n",
    "    y_temp = da.array(y_temp)\n",
    "    y = da.from_array(y_temp,chunks = {0:512})\n",
    "    #print(\"Completed....\")\n",
    "    return (X_events,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feed_dask = delayed(input_feed) # Delayed function does lazy computation on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (input_feed_dask)(event_grouped) # delayed output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_events = a[0]\n",
    "y_events = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Delayed('getitem-a5720561b354d5e13fa9ff81d95d308e'),\n",
       " Delayed('getitem-5bbac8d59dc1f684b92b721666e1dba3'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_events, y_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_events_ar = da.from_delayed(X_events,dtype= float ,shape = (1202267, 50))\n",
    "y_events = da.from_delayed(y_events,dtype = float, shape = (1202267,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_events_ar = X_events_ar.rechunk({0:512,1:-1})\n",
    "y_events = y_events.rechunk({0:512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkList = [(x,y) for x,y in zip(range(0,X_events_ar.shape[0]+X_events_ar.chunksize[0],\n",
    "                    X_events_ar.chunksize[0]),\n",
    "                    range(X_events_ar.chunksize[0],X_events_ar.shape[0]+X_events_ar.chunksize[0],\n",
    "                                                    X_events_ar.chunksize[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunkList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator function to stream batches to LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_inputs(x,y_array):\n",
    "    for chunks in chunkList:\n",
    "        X = x[chunks[0]:chunks[1]]\n",
    "        X = X.map_blocks(np.copy)\n",
    "        X = X.compute()\n",
    "        y = y_array[chunks[0]:chunks[1]]\n",
    "        y = y.map_blocks(np.copy)\n",
    "        y = y.compute()\n",
    "        y_transformed = np.zeros((len(y),27))\n",
    "        y_transformed[np.arange(len(y)),y] = 1\n",
    "        yield (X,y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = gen_inputs(X_events_ar, y_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 'glorot_uniform'\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(w2vmodel.wv.vocab),100,input_length= 50, \n",
    "                    weights = [embedding_matrix], trainable = False))\n",
    "model.add(LSTM(100,implementation =2 , kernel_initializer = init, return_sequences = False))\n",
    "model.add(Dense(50,kernel_initializer = init, activation = 'relu'))\n",
    "model.add(Dense(27,kernel_initializer = init, activation = 'softmax' , name =\"output\"))\n",
    "print(model.summary())\n",
    "model.compile(loss ='categorical_crossentropy',optimizer= 'rmsprop', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = model.fit_generator(inp, steps_per_epoch= np.ceil(1202267/512),verbose =1\n",
    "                         ,use_multiprocessing = True, workers = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model by loading data in RAM\n",
    "\n",
    "- Training is faster as ther is no overhead on CPU side to compute Dask graph for every input batch\n",
    "- Drawback : with larger dataset RAM could run out of Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_feed(series):\n",
    "    X_temp , y_temp = [], []\n",
    "    for event in series:\n",
    "        for i in range(1, len(event)):\n",
    "            temp_x = event[0:i]\n",
    "            temp_x = [w2vmodel.wv.vocab.get(x).index for x in temp_x]\n",
    "            #print(temp_x)\n",
    "            X_temp.append(temp_x)\n",
    "            temp_y = w2vmodel.wv.vocab.get(event[i]).index\n",
    "            y_temp.append(temp_y)\n",
    "    \n",
    "    X_events = pad_sequences(X_temp,maxlen= 50)\n",
    "    y_temp = np.array(y_temp)\n",
    "    #y = da.from_array(y_temp,chunks = {0:512})\n",
    "    #print(\"Completed....\")\n",
    "    return (X_events,y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = event_grouped.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "94215      [A_Create Application, W_Complete application,...\n",
       "919303     [A_Create Application, A_Concept, W_Complete a...\n",
       "2528658    [A_Create Application, A_Submitted, W_Handle l...\n",
       "2595810    [A_Create Application, A_Concept, W_Complete a...\n",
       "3108939    [A_Create Application, A_Concept, W_Complete a...\n",
       "Name: event:concept:name, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_events, y_events = input_feed(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1202267, 50), (1202267,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_events.shape, y_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_transformed = np.zeros((len(y_events),27))\n",
    "y_transformed[np.arange(len(y_events)),y_events] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1202267, 27)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 100)           2700      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 27)                1377      \n",
      "=================================================================\n",
      "Total params: 89,527\n",
      "Trainable params: 86,827\n",
      "Non-trainable params: 2,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "init = 'glorot_uniform'\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(w2vmodel.wv.vocab),100,input_length= 50, \n",
    "                    weights = [embedding_matrix], trainable = False))\n",
    "model.add(LSTM(100,implementation =2 , kernel_initializer = init, return_sequences = False))\n",
    "model.add(Dense(50,kernel_initializer = init, activation = 'relu'))\n",
    "model.add(Dense(27,kernel_initializer = init, activation = 'softmax' , name =\"output\"))\n",
    "print(model.summary())\n",
    "model.compile(loss ='categorical_crossentropy',optimizer= 'rmsprop', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1202267/1202267 [==============================] - 109s 91us/step - loss: 0.3991 - acc: 0.8630\n",
      "Epoch 2/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3255 - acc: 0.8791\n",
      "Epoch 3/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3204 - acc: 0.8800\n",
      "Epoch 4/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3181 - acc: 0.8806\n",
      "Epoch 5/20\n",
      "1202267/1202267 [==============================] - 111s 93us/step - loss: 0.3169 - acc: 0.8808\n",
      "Epoch 6/20\n",
      "1202267/1202267 [==============================] - 112s 93us/step - loss: 0.3160 - acc: 0.8810\n",
      "Epoch 7/20\n",
      "1202267/1202267 [==============================] - 111s 93us/step - loss: 0.3156 - acc: 0.8810\n",
      "Epoch 8/20\n",
      "1202267/1202267 [==============================] - 111s 93us/step - loss: 0.3153 - acc: 0.8812\n",
      "Epoch 9/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3152 - acc: 0.8812\n",
      "Epoch 10/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3153 - acc: 0.8813\n",
      "Epoch 11/20\n",
      "1202267/1202267 [==============================] - 110s 91us/step - loss: 0.3155 - acc: 0.8814\n",
      "Epoch 12/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3155 - acc: 0.8814\n",
      "Epoch 13/20\n",
      "1202267/1202267 [==============================] - 111s 93us/step - loss: 0.3157 - acc: 0.8813\n",
      "Epoch 14/20\n",
      "1202267/1202267 [==============================] - 111s 93us/step - loss: 0.3159 - acc: 0.8813\n",
      "Epoch 15/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3161 - acc: 0.8814\n",
      "Epoch 16/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3162 - acc: 0.8812\n",
      "Epoch 17/20\n",
      "1202267/1202267 [==============================] - 111s 93us/step - loss: 0.3164 - acc: 0.8813\n",
      "Epoch 18/20\n",
      "1202267/1202267 [==============================] - 110s 92us/step - loss: 0.3165 - acc: 0.8813\n",
      "Epoch 19/20\n",
      "1202267/1202267 [==============================] - 111s 92us/step - loss: 0.3166 - acc: 0.8813\n",
      "Epoch 20/20\n",
      "1202267/1202267 [==============================] - 110s 91us/step - loss: 0.3172 - acc: 0.8813\n"
     ]
    }
   ],
   "source": [
    "est = model.fit(X_events,y_transformed, batch_size= 512 , epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
